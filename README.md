# PPO (JAX)

(Work in progress)

Custom implementation of Proximal Policy Optimization (PPO) for continuous action space based on example code from [Flax](https://github.com/google/flax). Intended to support OpenAI Gym type environments or custom environments that have the same implementation.
